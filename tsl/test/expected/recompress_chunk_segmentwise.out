-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
\c :TEST_DBNAME :ROLE_SUPERUSER
CREATE OR REPLACE VIEW compressed_chunk_info_view AS
SELECT
   h.schema_name AS hypertable_schema,
   h.table_name AS hypertable_name,
   c.schema_name as chunk_schema,
   c.table_name as chunk_name,
   c.status as chunk_status,
   comp.schema_name as compressed_chunk_schema,
   comp.table_name as compressed_chunk_name
FROM
   _timescaledb_catalog.hypertable h JOIN
  _timescaledb_catalog.chunk c ON h.id = c.hypertable_id
   LEFT JOIN _timescaledb_catalog.chunk comp
ON comp.id = c.compressed_chunk_id
;
------------- only one segment exists and only one segment affected ---------
create table mytab_oneseg (time timestamptz not null, a int, b int, c int);
SELECT create_hypertable('mytab_oneseg', 'time', chunk_time_interval => interval '1 day');
     create_hypertable     
---------------------------
 (1,public,mytab_oneseg,t)
(1 row)

insert into mytab_oneseg values 
('2023-01-01 21:56:20.048355+02'::timestamptz, 2, NULL, 2),
('2023-01-01 21:56:10.048355+02'::timestamptz, 2, NULL, 2); --same chunk same segment
alter table mytab_oneseg set (timescaledb.compress, timescaledb.compress_segmentby = 'a, c');
select show_chunks as chunk_to_compress_1 from show_chunks('mytab_oneseg') limit 1 \gset 
select compress_chunk(:'chunk_to_compress_1');
             compress_chunk             
----------------------------------------
 _timescaledb_internal._hyper_1_1_chunk
(1 row)

SELECT compressed_chunk_schema || '.' || compressed_chunk_name as compressed_chunk_name_1
from compressed_chunk_info_view where hypertable_name = 'mytab_oneseg' \gset
SELECT ctid, * FROM :compressed_chunk_name_1;
 ctid  |                                 time                                 | a | b | c | _ts_meta_count | _ts_meta_sequence_num |           _ts_meta_min_1            |           _ts_meta_max_1            
-------+----------------------------------------------------------------------+---+---+---+----------------+-----------------------+-------------------------------------+-------------------------------------
 (0,1) | BAAAApQ3/qlnY///////Z2mAAAAAAgAAAAIAAAAAAAAA7gAFKG/+g/vGAAUob/+1KMU= | 2 |   | 2 |              2 |                    10 | Sun Jan 01 11:56:10.048355 2023 PST | Sun Jan 01 11:56:20.048355 2023 PST
(1 row)

insert into mytab_oneseg values ('2023-01-01 19:56:20.048355+02'::timestamptz, 2, NULL, 2);
select _timescaledb_internal.recompress_chunk_segmentwise(:'chunk_to_compress_1');
      recompress_chunk_segmentwise      
----------------------------------------
 _timescaledb_internal._hyper_1_1_chunk
(1 row)

-- check the ctid of the rows in the recompressed chunk to verify that we've written new data
SELECT ctid, * FROM :compressed_chunk_name_1;
 ctid  |                                       time                                       | a | b | c | _ts_meta_count | _ts_meta_sequence_num |           _ts_meta_min_1            |           _ts_meta_max_1            
-------+----------------------------------------------------------------------------------+---+---+---+----------------+-----------------------+-------------------------------------+-------------------------------------
 (0,2) | BAAAApQ2Uhq14/////5TcU6AAAAAAwAAAAMAAAAAAAAO7gAFKG/+g/vGAAUob/+1KMUAAAADV+w1/w== | 2 |   | 2 |              3 |                    10 | Sun Jan 01 09:56:20.048355 2023 PST | Sun Jan 01 11:56:20.048355 2023 PST
(1 row)

---------------- test1: one affected segment, one unaffected --------------
-- unaffected segment will still be recompressed in a future PR we want to avoid doing this
create table mytab_twoseg (time timestamptz not null, a int, b int, c int);
SELECT create_hypertable('mytab_twoseg', 'time', chunk_time_interval => interval '1 day');
     create_hypertable     
---------------------------
 (3,public,mytab_twoseg,t)
(1 row)

insert into mytab_twoseg values 
('2023-01-01 21:56:20.048355+02'::timestamptz, 2, NULL, 2),
('2023-01-01 21:56:20.048355+02'::timestamptz, 3, NULL, 3), --same chunk diff segment
('2023-01-01 21:57:20.048355+02'::timestamptz, 3, NULL, 3);
alter table mytab_twoseg set (timescaledb.compress, timescaledb.compress_segmentby = 'a, c');
select show_chunks as chunk_to_compress_2 from show_chunks('mytab_twoseg') limit 1 \gset 
select compress_chunk(:'chunk_to_compress_2');
             compress_chunk             
----------------------------------------
 _timescaledb_internal._hyper_3_3_chunk
(1 row)

insert into mytab_twoseg values ('2023-01-01 19:56:20.048355+02'::timestamptz, 2, NULL, 2);
select * from :chunk_to_compress_2;
                time                 | a | b | c 
-------------------------------------+---+---+---
 Sun Jan 01 11:56:20.048355 2023 PST | 2 |   | 2
 Sun Jan 01 11:57:20.048355 2023 PST | 3 |   | 3
 Sun Jan 01 11:56:20.048355 2023 PST | 3 |   | 3
 Sun Jan 01 09:56:20.048355 2023 PST | 2 |   | 2
(4 rows)

SELECT compressed_chunk_schema || '.' || compressed_chunk_name as compressed_chunk_name_2
from compressed_chunk_info_view where hypertable_name = 'mytab_twoseg' \gset
select ctid, * from :compressed_chunk_name_2;
 ctid  |                                 time                                 | a | b | c | _ts_meta_count | _ts_meta_sequence_num |           _ts_meta_min_1            |           _ts_meta_max_1            
-------+----------------------------------------------------------------------+---+---+---+----------------+-----------------------+-------------------------------------+-------------------------------------
 (0,1) | BAAAApQ3/0H94wAClDf/Qf3jAAAAAQAAAAEAAAAAAAAADgAFKG/+g/vG             | 2 |   | 2 |              1 |                    10 | Sun Jan 01 11:56:20.048355 2023 PST | Sun Jan 01 11:56:20.048355 2023 PST
 (0,2) | BAAAApQ3/0H94//////8bHkAAAAAAgAAAAIAAAAAAAAA7gAFKHAFqwnGAAUocAzSF8U= | 3 |   | 3 |              2 |                    10 | Sun Jan 01 11:56:20.048355 2023 PST | Sun Jan 01 11:57:20.048355 2023 PST
(2 rows)

select _timescaledb_internal.recompress_chunk_segmentwise(:'chunk_to_compress_2');
      recompress_chunk_segmentwise      
----------------------------------------
 _timescaledb_internal._hyper_3_3_chunk
(1 row)

-- verify that metadata count looks good
select ctid, * from :compressed_chunk_name_2;
 ctid  |                                 time                                 | a | b | c | _ts_meta_count | _ts_meta_sequence_num |           _ts_meta_min_1            |           _ts_meta_max_1            
-------+----------------------------------------------------------------------+---+---+---+----------------+-----------------------+-------------------------------------+-------------------------------------
 (0,3) | BAAAApQ2Uhq14/////5S2LgAAAAAAgAAAAIAAAAAAAAA7gAFKG/+g/vGAAUoc1jSi8U= | 2 |   | 2 |              2 |                    10 | Sun Jan 01 09:56:20.048355 2023 PST | Sun Jan 01 11:56:20.048355 2023 PST
 (0,4) | BAAAApQ3/0H94//////8bHkAAAAAAgAAAAIAAAAAAAAA7gAFKHAFqwnGAAUocAzSF8U= | 3 |   | 3 |              2 |                    10 | Sun Jan 01 11:56:20.048355 2023 PST | Sun Jan 01 11:57:20.048355 2023 PST
(2 rows)

-- verify that initial data is returned as expected
select * from :chunk_to_compress_2;
                time                 | a | b | c 
-------------------------------------+---+---+---
 Sun Jan 01 11:56:20.048355 2023 PST | 2 |   | 2
 Sun Jan 01 09:56:20.048355 2023 PST | 2 |   | 2
 Sun Jan 01 11:57:20.048355 2023 PST | 3 |   | 3
 Sun Jan 01 11:56:20.048355 2023 PST | 3 |   | 3
(4 rows)

----------------- more than one batch per segment ----------------------
-- test that metadata sequence number is correct
create table mytab2(time timestamptz not null, a int, b int, c int);
select create_hypertable('mytab2', 'time', chunk_time_interval => interval '1 week');
  create_hypertable  
---------------------
 (5,public,mytab2,t)
(1 row)

insert into mytab2 (time, a, c) select t,s,s from 
generate_series('2023-01-01 00:00:00+00'::timestamptz, '2023-01-01 00:00:00+00'::timestamptz + interval '1 day', interval '30 sec') t cross join generate_series(0,2, 1) s;
alter table mytab2 set (timescaledb.compress, timescaledb.compress_segmentby = 'a, c');
select compress_chunk(c) from show_chunks('mytab2') c;  
             compress_chunk             
----------------------------------------
 _timescaledb_internal._hyper_5_5_chunk
(1 row)

SELECT compressed_chunk_schema || '.' || compressed_chunk_name as compressed_chunk_name_2
from compressed_chunk_info_view where hypertable_name = 'mytab2' 
and compressed_chunk_name is not null limit 1 \gset
insert into mytab2 values ('2023-01-01 00:00:02+00'::timestamptz, 0, NULL, 0); -- goes into the uncompressed chunk
select show_chunks('mytab2') as chunk_to_compress_2 \gset
select ctid, * from :compressed_chunk_name_2;
 ctid  |                                       time                                       | a | b | c | _ts_meta_count | _ts_meta_sequence_num |        _ts_meta_min_1        |        _ts_meta_max_1        
-------+----------------------------------------------------------------------------------+---+---+---+----------------+-----------------------+------------------------------+------------------------------
 (0,1) | BAAAApQ0bFLXgP/////+NjyAAAAD6AAAAAMAAAAAAAAP7gAFKHbNWYAAAAUodtDtBv8AAD5gAAAAAA== | 0 |   | 0 |           1000 |                    10 | Sun Jan 01 07:40:30 2023 PST | Sun Jan 01 16:00:00 2023 PST
 (0,2) | BAAAApQtcC8rgP/////+NjyAAAAD6AAAAAMAAAAAAAAP7gAFKGjVEigAAAUoaNilrv8AAD5gAAAAAA== | 0 |   | 0 |           1000 |                    20 | Sat Dec 31 23:20:30 2022 PST | Sun Jan 01 07:40:00 2023 PST
 (0,3) | BAAAApQnSNVgAP/////+NjyAAAADcQAAAAMAAAAAAAAP7gAFKFrcytAAAAUoWuBeVv8AADbwAAAAAA== | 0 |   | 0 |            881 |                    30 | Sat Dec 31 16:00:00 2022 PST | Sat Dec 31 23:20:00 2022 PST
 (0,4) | BAAAApQ0bFLXgP/////+NjyAAAAD6AAAAAMAAAAAAAAP7gAFKHbNWYAAAAUodtDtBv8AAD5gAAAAAA== | 1 |   | 1 |           1000 |                    10 | Sun Jan 01 07:40:30 2023 PST | Sun Jan 01 16:00:00 2023 PST
 (0,5) | BAAAApQtcC8rgP/////+NjyAAAAD6AAAAAMAAAAAAAAP7gAFKGjVEigAAAUoaNilrv8AAD5gAAAAAA== | 1 |   | 1 |           1000 |                    20 | Sat Dec 31 23:20:30 2022 PST | Sun Jan 01 07:40:00 2023 PST
 (0,6) | BAAAApQnSNVgAP/////+NjyAAAADcQAAAAMAAAAAAAAP7gAFKFrcytAAAAUoWuBeVv8AADbwAAAAAA== | 1 |   | 1 |            881 |                    30 | Sat Dec 31 16:00:00 2022 PST | Sat Dec 31 23:20:00 2022 PST
 (0,7) | BAAAApQ0bFLXgP/////+NjyAAAAD6AAAAAMAAAAAAAAP7gAFKHbNWYAAAAUodtDtBv8AAD5gAAAAAA== | 2 |   | 2 |           1000 |                    10 | Sun Jan 01 07:40:30 2023 PST | Sun Jan 01 16:00:00 2023 PST
 (0,8) | BAAAApQtcC8rgP/////+NjyAAAAD6AAAAAMAAAAAAAAP7gAFKGjVEigAAAUoaNilrv8AAD5gAAAAAA== | 2 |   | 2 |           1000 |                    20 | Sat Dec 31 23:20:30 2022 PST | Sun Jan 01 07:40:00 2023 PST
 (0,9) | BAAAApQnSNVgAP/////+NjyAAAADcQAAAAMAAAAAAAAP7gAFKFrcytAAAAUoWuBeVv8AADbwAAAAAA== | 2 |   | 2 |            881 |                    30 | Sat Dec 31 16:00:00 2022 PST | Sat Dec 31 23:20:00 2022 PST
(9 rows)

select _timescaledb_internal.recompress_chunk_segmentwise(:'chunk_to_compress_2');
      recompress_chunk_segmentwise      
----------------------------------------
 _timescaledb_internal._hyper_5_5_chunk
(1 row)

select ctid, * from :compressed_chunk_name_2;
  ctid  |                                           time                                           | a | b | c | _ts_meta_count | _ts_meta_sequence_num |        _ts_meta_min_1        |        _ts_meta_max_1        
--------+------------------------------------------------------------------------------------------+---+---+---+----------------+-----------------------+------------------------------+------------------------------
 (0,10) | BAAAApQ0bFLXgP/////+NjyAAAAD6AAAAAMAAAAAAAAP7gAFKHbNWYAAAAUodtDtBv8AAD5gAAAAAA==         | 0 |   | 0 |           1000 |                    10 | Sun Jan 01 07:40:30 2023 PST | Sun Jan 01 16:00:00 2023 PST
 (0,11) | BAAAApQtcC8rgP/////+NjyAAAAD6AAAAAMAAAAAAAAP7gAFKGjVEigAAAUoaNilrv8AAD5gAAAAAA==         | 0 |   | 0 |           1000 |                    20 | Sat Dec 31 23:20:30 2022 PST | Sun Jan 01 07:40:00 2023 PST
 (0,12) | BAAAApQnSNVgAP//////4XuAAAADcgAAAAQAAAAAAADf7gAFKFrcytAAAAUoWuBeVv8AADbgAAAAAAMZdQAAPQkA | 0 |   | 0 |            882 |                    30 | Sat Dec 31 16:00:00 2022 PST | Sat Dec 31 23:20:00 2022 PST
 (0,13) | BAAAApQ0bFLXgP/////+NjyAAAAD6AAAAAMAAAAAAAAP7gAFKHbNWYAAAAUodtDtBv8AAD5gAAAAAA==         | 1 |   | 1 |           1000 |                    10 | Sun Jan 01 07:40:30 2023 PST | Sun Jan 01 16:00:00 2023 PST
 (0,14) | BAAAApQtcC8rgP/////+NjyAAAAD6AAAAAMAAAAAAAAP7gAFKGjVEigAAAUoaNilrv8AAD5gAAAAAA==         | 1 |   | 1 |           1000 |                    20 | Sat Dec 31 23:20:30 2022 PST | Sun Jan 01 07:40:00 2023 PST
 (0,15) | BAAAApQnSNVgAP/////+NjyAAAADcQAAAAMAAAAAAAAP7gAFKFrcytAAAAUoWuBeVv8AADbwAAAAAA==         | 1 |   | 1 |            881 |                    30 | Sat Dec 31 16:00:00 2022 PST | Sat Dec 31 23:20:00 2022 PST
 (0,16) | BAAAApQ0bFLXgP/////+NjyAAAAD6AAAAAMAAAAAAAAP7gAFKHbNWYAAAAUodtDtBv8AAD5gAAAAAA==         | 2 |   | 2 |           1000 |                    10 | Sun Jan 01 07:40:30 2023 PST | Sun Jan 01 16:00:00 2023 PST
 (0,17) | BAAAApQtcC8rgP/////+NjyAAAAD6AAAAAMAAAAAAAAP7gAFKGjVEigAAAUoaNilrv8AAD5gAAAAAA==         | 2 |   | 2 |           1000 |                    20 | Sat Dec 31 23:20:30 2022 PST | Sun Jan 01 07:40:00 2023 PST
 (0,18) | BAAAApQnSNVgAP/////+NjyAAAADcQAAAAMAAAAAAAAP7gAFKFrcytAAAAUoWuBeVv8AADbwAAAAAA==         | 2 |   | 2 |            881 |                    30 | Sat Dec 31 16:00:00 2022 PST | Sat Dec 31 23:20:00 2022 PST
(9 rows)

